本文件夹当中的预训练模型是一个参数较小的中文预训练模型，具体参数如下：<br>
Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters<br>
其中有五个文件：<br>
*	3个bert_model.ckpt开头的文件是负责模型变量载入
*	vocab.txt是训练时中文文本采用的字典
*	bert_config.json是BERT在训练时，可选调整的一些参数<br>
由于有一个.ckpt文件太大，未上传；整个文件[下载地址](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip)

